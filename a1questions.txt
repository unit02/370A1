1. Look at the list of processes, arrival times and burst times on page 270 of the text. Draw a Gantt chart (ASCII art is suitable) showing the order of execution for these processes if they were scheduled by a LIFO stack-based dispatcher. What would the average waiting time be in this case?


2. The code commented out in Process.main_process_body method checks the processâ€™ state. A real implementation wouldn't require this. Explain why a real system doesn't require this and why a Python thread implementation does. Alternatively explain how you could get rid of this even when using Python threads.

A real system does not require any state checks due to the fact that at the system level, the system knows the state of the thread.  The decisions regarding which processes to run and pause are made by the scheduler implemented. Usually, the scheduler maintains lists of which threads a runnable and waiting, and thus are able to simply look into the lists to find the next thread to run in an action called a context switch.

3. (For SOFTENG370 students only). Does the solution of maintaining one stack shared by multiple processors scale well? Explain.

Maintaining one stack for multiple processors does not scale well due to issues with synchronization. Examples of these issues were presented in the lectures, with lock distribution during critical sections being the cause of great strife. A solution presented was that of spin-locks / busy waits. The use of this solution presents a major issue - if two processors access the stack at the same time, they would both see that is is unlocked, and concurrently gain the write lock, leading to a possible loss or corruption of data. 

Another solution presented was that of adding priorities to tasks, then using those priorities to gain the lock. This used in conjunction with a single stack accessed concurrently by multiple processors is unlikely to scale well, due to the issue of certain low-priority tasks never being executed, especially when there are multiple processors. Synchronizing the priorities over the processors is also an issue.

A solution to this would be to have a stack per processor, then after each processor has completed its own actions, the stacks are merged. This however solution is rather resource heavy, and not very realistic. 


P1 : 19-1 = 18 secs
P2 : 16-2 = 14 secs
P3 : 8-3  =5

18 + 14	+5 / 4 
=9.25 average waiting time
